# Руководство по запуску и логированию ассистента `sd_ass_2`

Этот файл содержит практическую информацию о том, как развернуть и запустить ассистент **sd_ass_2**, а также описывает систему логирования.  Для общей архитектуры и описания компонентов смотрите файл `report.md`.

## Требования

- **Python ≥ 3.10**. Проект разрабатывался на Python 3.12.
- **Git** для клонирования репозитория.
- Рекомендуется создать изолированную среду (`venv` или `conda`).
- При использовании моделей GPU – установленный CUDA и драйверы (см. `gpu.sh` для проверки).

## Установка

1. Склонируйте репозиторий:

   ```bash
   git clone https://github.com/gbvolkov/sd_ass_2.git
   cd sd_ass_2
   ```

2. Создайте виртуальную среду и активируйте её:

   ```bash
   python -m venv .venv
   source .venv/bin/activate  # Linux/macOS
   .venv\Scripts\activate    # Windows
   ```

3. Установите зависимости:

   ```bash
   pip install --upgrade pip
   pip install -r requirements.txt
   ```

## Настройка переменных окружения

Большинство секретных параметров передаются через переменные окружения.  Рекомендуется создать файл `gv.env` в корне проекта со следующими переменными (пример):

```ini
TELEGRAM_ASSISTANT_BOT_TOKEN=<токен_вашего_бота>

# Параметры выбранных LLM‑провайдеров (задавайте те, которые нужны)
OPENAI_API_KEY=<ключ_OpenAI>
GIGA_CHAT_USER_ID=<идентификатор_GigaChat>
GIGA_CHAT_SECRET=<секрет_GigaChat>
GIGA_CHAT_AUTH=<токен_GigaChat>
YA_API_KEY=<api_key_Yandex_GPT>
YA_FOLDER_ID=<folder_id_Yandex_GPT>
YA_AUTH_TOKEN=<iam_token_Yandex_GPT>
GEMINI_API_KEY=<api_key_Gemini>

# Параметры Teamly/Google Sheets
USERS_SHEET_ID=<id_таблицы_пользователей>
FEEDBACK_SHEET_ID=<id_таблицы_оценок>
GOOGLE_SHEETS_CRED=<путь_к_service_account.json>

# Модели для поиска и ранжирования
EMBEDDING_MODEL=/models/multilingual-e5-large
RERANKING_MODEL=/models/bge-reranker-large
WHISPER_MODEL=small
WHISPER_MODEL_PATH=/models/whisper_small

# Общие параметры
LLM_PROVIDER=openai         # openai, gigachat, yandex, mistral, gemini
TEAM_GPT_MODEL=nano         # nano, mini или base
RETRIEVER_TYPE=teamly       # teamly или faiss
BOT_MODE=polling            # polling или webhook
UPD_TIMEOUT=300             # интервал обновления индексов KB (секунды)
USE_ANONIMIZER=False        # включить анонимизацию
DEBUG_WORKFLOW=False        # включить отладочный вывод LangGraph

# Параметры webhook (если BOT_MODE=webhook)
WEBHOOK_BASE=https://<ваш_домен>
WEBAPP_HOST=0.0.0.0
WEBAPP_PORT=8080
WEBHOOK_PATH=/tg-webhook
WEBHOOK_SECRET=<секрет_webhook>
```

После создания файла перезапустите бот.  `config.py` автоматически загрузит переменные из `gv.env` (или из `~/.env`), поэтому перед запуском убедитесь, что файл доступен.

## Запуск бота

### Основной режим (polling)

1. Убедитесь, что `BOT_MODE` установлена в `polling` (значение по умолчанию).
2. Запустите бота напрямую:

   ```bash
   python sd_ass_bot.py
   ```

   Бот подключится к Telegram и будет прослушивать входящие сообщения.  Сообщения и ошибки будут выводиться в консоль.

3. Для запуска в фоновом режиме используйте скрипт `start.sh`.  Он запускает бота через `nohup` и сохраняет PID в файле `.process`:

   ```bash
   ./start.sh
   ```

   Вывод будет записываться в `nohup.out`.  Чтобы остановить фоновый процесс, выполните `kill.sh`:

   ```bash
   ./kill.sh
   ```

4. При необходимости проверить ошибки и активный процесс можно через скрипт `check.sh`:

   ```bash
   ./check.sh
   ```

### Режим webhook

Если вы хотите получать обновления через webhook, установите переменную `BOT_MODE=webhook` и настройте параметры `WEBHOOK_BASE`, `WEBAPP_HOST`, `WEBAPP_PORT`, `WEBHOOK_PATH` и `WEBHOOK_SECRET`.  Запуск аналогичен:

```bash
python sd_ass_bot.py
```

Бот запустит веб‑сервер `aiohttp` и зарегистрирует webhook у Telegram.  Убедитесь, что указанный домен (`WEBHOOK_BASE`) публично доступен и что порт (`WEBAPP_PORT`) открыт.

## Обновление индексов базы знаний

Ассистент использует локальные индексы для поиска статей, тикетов и глоссария.  Их можно обновлять вручную или автоматически:

- Для автоматического обновления укажите `UPD_TIMEOUT` в секундах.  Задача обновления будет запускаться в фоне (`PeriodicTask`), её можно приостановить/возобновить через команды бота.
- Для ручного обновления отправьте команду `/reload` в чат с ботом.  Она вызовет `refresh_indexes` из модуля `agents.retrievers.utils.load_common_retrievers`.

## Работа с GPU

По умолчанию код использует GPU, если он доступен.  Чтобы отключить использование GPU (например, на CPU‑сервере), установите переменную окружения `NO_CUDA=True`.  Скрипт `gpu.sh` позволяет проверить доступные GPU:

```bash
./gpu.sh
```

## Логирование

Приложение ведёт несколько видов логов:

### 1. Консольные / `nohup.out`

При запуске в обычном режиме сообщения (`INFO`, `WARNING`, `ERROR`) выводятся в консоль через стандартный модуль `logging`.  При запуске скриптом `start.sh` вывод перенаправляется в файл `nohup.out`.  Чтобы просмотреть последние ошибки, выполните `./check.sh`, который выводит строки с `ERROR` из `nohup.out`.

### 2. Логи LLM и инструментов (`logs/sd_ass_<timestamp>`)

Внутри `agents/agent.py` при инициализации агента создаётся файл логов вида `./logs/sd_ass_YYYYMMDDHHMM`.  Ведутся события с помощью класса `JSONFileTracer` из `utils/llm_logger.py`.  Каждый лог записывается в формате JSON Lines.  Поля:

| Поле | Значение |
|---|---|
| **ts** | Временная метка в секундах (Unix). |
| **type** | Тип события: `llm_start`, `llm_end`, `tool_start`, `tool_end`. |
| **model** | Модель LLM, которая была вызвана. |
| **prompt** | Текст запроса, отправленного в модель (для `llm_start`). |
| **response** | Сгенерированный ответ (для `llm_end`)【33712963318412†L3-L21】. |
| **tool** | Имя вызванного инструмента (для `tool_start`). |
| **input** | Входные данные инструмента (для `tool_start`). |
| **output** | Результат работы инструмента (для `tool_end`). |

Пример строки:

```json
{"ts": 1713801123.72, "type": "llm_start", "model": {"id": "gpt-4.1"}, "prompt": ["Кто такие кей юзеры?"]}
```

### 3. Логи анонимизации (`logs/LLM_requests_log_<timestamp>`)

Если в `config.py` переменная `USE_ANONIMIZER=True`, ассистент будет заменять персональные данные (ФИО, паспортные данные, телефоны и т.д.) с помощью библиотеки **Palimpsest**.  До и после анонимизации сообщения записываются в файл `./logs/LLM_requests_log_<timestamp>`.  Лог содержит исходный и очищенный текст.  Это полезно для аудита, но может содержать частичные фрагменты исходных данных, поэтому храните его безопасно.

### 4. Google Sheets (оценки пользователей)

Когда пользователь оценивает ответ бота (клавиши «Промазал», «Похоже на правду», «В точку»), данные отправляются в таблицу Google Sheets, указанную в `FEEDBACK_SHEET_ID`.  Сам процесс логируется в `nohup.out`.  Для обработки и перемещения оценённых записей используйте методы из `store_managers/google_sheets_man.py`.

## Дополнительные команды

- **/help** – выводит краткую справку и доступные команды.
- **/sber**, **/gpt** – переключают используемую модель на GigaChat или GPT соответственно.
- **/reset** – очищает память агента, что полезно перед началом нового обсуждения.
- **/users** – доступна администраторам; отображает список зарегистрированных пользователей и разрешённых моделей.

## Советы по эксплуатации

* По умолчанию индексы базы знаний хранятся в каталогах `./data/notion_idx`, `./data/chats_idx` и `./data/ass_idx`.  Убедитесь, что у процесса есть права на запись в эти каталоги.
* При первом запуске загрузка и построение индексов может занять значительное время, особенно если используется большой глоссарий и объёмная база тикетов.
* Следите за актуальностью ключей и токенов; большинство API (Yandex, GigaChat, Google) имеют срок действия.
* Если бот не отвечает, проверьте файл `nohup.out` и лог `./logs/...` на наличие ошибок.  Часто проблемы связаны с некорректными токенами или отсутствием доступа к интернету.

---

После выполнения этих шагов вы сможете запустить ассистент и мониторить его работу.  Для деталей архитектуры и описания компонентов см. файл `developer.md`.